import { Code } from "@mdx"

export const metadata = {
    slug: "homelab-part-2-kubernetes",
    title: "Homelab Part 2, Kubernetes",
    description: "Configuring Kubernetes and ArgoCD for my homelab",
};
 
In the last part of the Homelab series, we configured Terraform so our VPS can effectively be spawned and despawned via commands.
Now we need to configure our homelab so we can use it to deploy and test applications. Basically, we need to run Kubernetes on our server.

## Many types of Kubernetes

There are six main ways to run Kubernetes on a server (IDK there might be more):

[Talos](https://www.talos.dev/) - Basically a fully fledged Linux distro made for Kubernetes, communication is done via an API, hence minimal, secure and production grade.

[Kubeadm](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/) - Made by Kubernetes themselves, no out-of-the-box experience, needs setup and is hard to manage.

[K3s](https://k3s.io/) - Optimized, constrained mini K8s distribution, low production grade, easy to manage.

[K0s](https://k0sproject.io/) - Production grade bare metal K8s distro, minimal and self-contained.

[Minikube](https://minikube.sigs.k8s.io/docs/) - Used for locally testing and development

[MicroK8s](https://microk8s.io/) - Made by the guys who made Ubuntu, based on snap and plugins, heavier resource use.

## K3s

There are many Kubernetes distributions, but for now we are going to use k3s.

Why? It's easy to manage, has full Kubernetes API support, and can be used with Rancher ecosystems.

However, ideally we want to use Talos, because it's production grade and we need to be able to debug production grade clusters.

First of all, we'll need to edit our homelab.tf config to be able to download K3s.

You can refer to this [Guide](https://www.digitalocean.com/community/tutorials/how-to-setup-k3s-kubernetes-cluster-on-ubuntu) if you need more info.

Basically this command is enough for that.

<Code lang="bash" code={`
curl -sfL https://get.k3s.io | sh -
sudo chmod 644 /etc/rancher/k3s/k3s.yaml
`}/>

## ArgoCD

Now actually we have docker, kubectl and k3s installed. So we have a fully operational Kubernetes cluster waiting to be used.

But we're not going to stop there, we'll also be installing ArgoCD.

ArgoCD my beloved GitOps thingy. It makes a lot of things a lot more easier.

Anywho, this requires a little bit of configuring. First in our Cluster we can make a new namespace and install argocd via its manifest

<Code lang="bash" code={`
kubectl create namespace argocd
kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml
`}/>

Like so.

Then we'll need to wait until all of the argocd pods are done and running
<Code lang="bash" code={`
kubectl wait --for=condition=Ready pods --all -n argocd --timeout=300s
`}/>

Now ArgoCD is running in your Cluster, but the thing is we need to use the ArgoCD UI, but how?

You see when running ArgoCD in local machines it's easy to get its UI from the browser, but in a VPS like this, we may need to expose the ArgoCD UI via a NodePort

<Code lang="bash" code={`
kubectl patch svc argocd-server -n argocd -p '{"spec": {"type": "NodePort"}}'
`}/>

We can use the above command to patch the type of service to a NodePort, this exposes our ArgoCD UI via the VPS's IP address

You can then use this command to get all the details about the exposed ArgoCD service

<Code lang="bash" code={`
kubectl get svc argocd-server -n argocd
`}/>

You can access your ArgoCD UI using your IP address and the 443 mapped port number (let's assume it's 320001) like this: http://YOUR_IP_ADDRESS:320001

You will also need the password for ArgoCD, which can be retrieved using the following command (note that it's base64 encoded):

<Code lang="bash" code={`
kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d
`}/>

And that's how I installed kubernetes and exposed ArgoCD UI in homelab.